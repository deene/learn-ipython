{
 "metadata": {
  "name": "",
  "signature": "sha256:0eefc7e0f987570f4a86bab5fa505a307d0ef3cc712f1b32c509c15d7f2c645b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# This notebook is dedicated to the study of data mining"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How to download from Nature\n",
      "\n",
      "The below code downloads data from nature and save into json."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How to parse XML in Python?\n",
      "\n",
      "[This stackoverflow post](http://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python) explains how to use Python to parse XML.\n",
      "\n",
      "minidom is the quickest and pretty straight forward:\n",
      "\n",
      "```XML\n",
      "<data>\n",
      "    <items>\n",
      "        <item name=\"item1\"></item>\n",
      "        <item name=\"item2\"></item>\n",
      "        <item name=\"item3\"></item>\n",
      "        <item name=\"item4\"></item>\n",
      "    </items>\n",
      "</data>\n",
      "```\n",
      "\n",
      "```Python\n",
      "from xml.dom import minidom\n",
      "xmldoc = minidom.parse('items.xml')\n",
      "itemlist = xmldoc.getElementsByTagName('item') \n",
      "print len(itemlist)\n",
      "print itemlist[0].attributes['name'].value\n",
      "for s in itemlist :\n",
      "    print s.attributes['name'].value\n",
      "```\n",
      "\n",
      "```Output\n",
      "4\n",
      "item1\n",
      "item1\n",
      "item2\n",
      "item3\n",
      "item4\n",
      "```\n",
      "\n",
      "And I can use the ```s.childNodes[0].nodeValue``` to get the inner value.\n",
      "\n",
      "Below is the test code working on the nature-2010.xml that I downloaded from Nature. I can use the [intentXML](https://github.com/alek-sys/sublimetext_indentxml) sublime plugin to make the XML file look nicer."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But this code does not work as the xml file downloaded from nature is kind of [junky](http://stackoverflow.com/questions/26008046/xml-parsing-error-junk-after-document-element-in-twilio).\n",
      "\n",
      "So instead, I try the json approach. (use the [prettyJSON](https://github.com/dzhibas/SublimePrettyJson) sublime plugin to make the json file look nicer."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Python Class Learning\n",
      "\n",
      "In order to count the occurance of words in all texts, I need to create a WordCount class. This class should have a function which takes in a certain string, count the occurance of each word in that string, and add the result to the previously stored values in that class. So below is the code to make such a class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import json\n",
      "from pprint import pprint\n",
      "\n",
      "class WordCount:\n",
      "    \"\"\"A simple word count class\"\"\"\n",
      "    def __init__(self):\n",
      "        self.word_table = {}\n",
      "        self.msg = ''\n",
      "        self.ignore_list = ('of', 'the', 'a', 'to', 'and', 'in', 'be', 'as', \\\n",
      "                            'that', 'this', 'can', 'for', 'have', 'is', 'with', \\\n",
      "                            'by', 'are', 'used', 'such', 'on', 'it', 'at', 'from', \\\n",
      "                            'high', 'has', 'an', 'which', '(', ')', ',', 'made', 'its', \\\n",
      "                            'new', '2013', '.', 'two', '-', 'researchers', 'been', 'or', \\\n",
      "                            'using', 'state', '\\\u2014', 'not')\n",
      "\n",
      "    def append(self, string):\n",
      "        # print 'Analyzing...'\n",
      "        new_word_array = split_string.split()\n",
      "        \n",
      "        for aword in new_word_array:\n",
      "            # ignore the normal words\n",
      "            if aword in self.ignore_list:\n",
      "                continue\n",
      "            if aword in self.word_table:\n",
      "                # if the word exists, add 1\n",
      "                self.word_table[aword] = self.word_table[aword] + 1\n",
      "            else:\n",
      "                # if the word does not exist, init the key with 1\n",
      "                self.word_table[aword] = 1\n",
      "                \n",
      "        return self.msg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Codes to analyze the downloaded json file\n",
      "\n",
      "Now I need to take in the description of each entry from the json file and feed it into the WordCount class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "json_data=open('./Nature-record.json')\n",
      "data = json.load(json_data)\n",
      "word_count = WordCount()\n",
      "\n",
      "split_string = ''\n",
      "for entry in data['feed']['entry']:\n",
      "    if entry[u'dc:description']:\n",
      "        split_string = entry[u'dc:description'].replace('<p>', '').replace('-', ' ').lower()\n",
      "        word_count.append(split_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I have the need to sort word_table by each key value. So I take this chance and start to learn a bit about NumPy, SciPy and Pandas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import *\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a Series is to call:\n",
      "\n",
      "```\n",
      "s = Series(data, index=index)\n",
      "```\n",
      "\n",
      "Here, data can be many different things:\n",
      "\n",
      "- a Python dict\n",
      "- an ndarray\n",
      "- a scalar value (like 5)\n",
      "\n",
      "Here in this app, we use dict. Before counting the actual science words, I need to create a table containing all the \"normal\" english words such as 'as', 'of', 'but'. These words should be ignored in the counting. The word table will be screened against this normal word table to eliminate these words first. This is done inthe WordCount class's ignore_list - well, after some test, I found that the list can go so long that it is not practical to manually list it. Need some algo to construct such a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = Series(word_count.word_table)\n",
      "#print s.order()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'Series' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-4f815f956dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print s.order()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'Series' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I can use the order() and sort() function of a Series to sort the Series by value. order() returns a new array and sort() is in place."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Code to crawl Nature publications.\n",
      "\n",
      "The following code uses the Nature API to search for papers published in Nature."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import xml.etree.ElementTree as ET\n",
      "import urllib2, urllib\n",
      "import codecs\n",
      "import time\n",
      "\n",
      "content = None\n",
      "# build up a product code array, can be found at the A-Z page links on nature.com\n",
      "# build up a year=month=day array\n",
      "\n",
      "# Crawl nature\n",
      "print \"\\n\\nstart -----\"\n",
      "for year in range(2012, 2013):\n",
      "    fileName = 'nnano-' + str(year) + '.json'\n",
      "    myfile = open(fileName, 'w+')\n",
      "    myfile.write('[')\n",
      "    yearWord = str(year)\n",
      "\n",
      "    for month in range(1,13):\n",
      "        if month < 10:\n",
      "            monthWord =  '0' + str(month)\n",
      "        else:\n",
      "            monthWord = str(month)\n",
      "\n",
      "        for day in range(1,32):\n",
      "            if day<10:\n",
      "                dayWord = '0' + str(day)\n",
      "            else:\n",
      "                dayWord = str(day)\n",
      "\n",
      "            targetDate = yearWord + '-' + monthWord + '-' + dayWord\n",
      "            print targetDate,\n",
      "        \n",
      "            queryWord = 'prism.productCode=nnano+AND+prism.publicationDate=' + targetDate\n",
      "            url = 'http://api.nature.com/content/opensearch/request?&recordPacking=unpacked&queryType=cql&maximumRecords=100&httpAccept=application/json&query=' + queryWord\n",
      "\n",
      "            try:\n",
      "                content = urllib2.urlopen(url).read()\n",
      "                data = json.loads(content)\n",
      "            except:\n",
      "                print \"URL error\"\n",
      "                continue\n",
      "                    \n",
      "            if data['feed']['opensearch:totalResults'] != 0:\n",
      "                for entry in data['feed'][\"entry\"]:\n",
      "                    print entry[\"prism:publicationName\"] + ',' + entry[\"prism:publicationDate\"] + ',' + entry[\"dc:title\"] \\\n",
      "                          + ':' + entry[\"dc:description\"]\n",
      "                    json.dump(entry, myfile, indent=4)\n",
      "                    myfile.write(',')\n",
      "                #myfile.write(simplejson.dumps(simplejson.loads(output), indent=4, sort_keys=True))\n",
      "            else:\n",
      "                print \"No result found!\"\n",
      "            \n",
      "            time.sleep(1)\n",
      "    \n",
      "    myfile.write(']')\n",
      "    myfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "start -----\n",
        "2012-01-01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-02"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-06"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-07"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-09"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Nature Nanotechnology,2012-01-10,Vertical nanowire electrode arrays as a scalable platform for intracellular interfacing to neuronal circuits:<p>Deciphering the neuronal code\u2014the rules by which neuronal circuits store and process information\u2014is a major scientific challenge. Currently, these efforts are impeded by a lack of experimental tools that are sensitive enough to quantify the strength of individual synaptic connections and also scalable enough to simultaneously measure and control a large number of mammalian neurons with single-cell resolution. Here, we report a scalable intracellular electrode platform based on vertical nanowires that allows parallel electrical interfacing to multiple mammalian neurons. Specifically, we show that our vertical nanowire electrode arrays can intracellularly record and stimulate neuronal activity in dissociated cultures of rat cortical neurons and can also be used to map multiple individual synaptic connections. The scalability of this platform, combined with its compatibility with silicon nanofabrication techniques, provides a clear path towards simultaneous, high-fidelity interfacing with hundreds of individual neurons.</p>\n",
        "Nature Nanotechnology,2012-01-10,Photoluminescence imaging of electronic-impurity-induced exciton quenching in single-walled carbon nanotubes:<p>The electronic properties of single-walled carbon nanotubes can be altered by surface adsorption of electronic impurities or dopants. However, fully understanding the influence of these impurities is difficult because of the inherent complexity of the solution-based colloidal chemistry of nanotubes, and because of a lack of techniques for directly imaging dynamic processes involving these impurities. Here, we show that photoluminescence microscopy can be used to image exciton quenching in semiconducting single-walled carbon nanotubes during the early stages of chemical doping with two different species. The addition of AuCl<sub>3</sub> leads to localized exciton-quenching sites, which are attributed to a mid-gap electronic impurity level, and the adsorbed species are also found sometimes to be mobile on the surface of the nanotubes. The addition of H<sub>2</sub>O<sub>2</sub> leads to delocalized exciton-quenching hole states, which are responsible for long-range photoluminescence blinking, and are also mobile.</p>\n",
        "Nature Nanotechnology,2012-01-10,Probing and repairing damaged surfaces with nanoparticle-containing microcapsules:<p>Nanoparticles have useful properties, but it is often important that they only start working after they are placed in a desired location. The encapsulation of nanoparticles allows their function to be preserved until they are released at a specific time or location, and this has been exploited in the development of self-healing materials and in applications such as drug delivery. Encapsulation has also been used to stabilize and control the release of substances, including flavours, fragrances and pesticides. We recently proposed a new technique for the repair of surfaces called \u2018repair-and-go\u2019. In this approach, a flexible microcapsule filled with a solution of nanoparticles rolls across a surface that has been damaged, stopping to repair any defects it encounters by releasing nanoparticles into them, then moving on to the next defect. Here, we experimentally demonstrate the repair-and-go approach using droplets of oil that are stabilized with a polymer surfactant and contain CdSe nanoparticles. We show that these microcapsules can find the cracks on a surface and selectively deliver the nanoparticle contents into the crack, before moving on to find the next crack. Although the microcapsules are too large to enter the cracks, their flexible walls allow them to probe and adhere temporarily to the interior of the cracks. The release of nanoparticles is made possible by the thin microcapsule wall (comparable to the diameter of the nanoparticles) and by the favourable (hydrophobic\u2013hydrophobic) interactions between the nanoparticle and the cracked surface.</p>\n",
        "2012-01-11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n",
        "2012-01-12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " No result found!\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-71c07100f41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"No result found!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And the below code will crawl IEEE and Springer accordingly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "json_data=open('./nature-2012.json')\n",
      "data = json.load(json_data)\n",
      "print data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'prism:volume': u'7', u'prism:doi': u'10.1038/nnano.2011.249', u'dc:title': u'Vertical nanowire electrode arrays as a scalable platform for intracellular interfacing to neuronal circuits', u'prism:publicationName': u'Nature Nanotechnology', u'dc:publisher': u'Nature Publishing Group', u'prism:productCode': u'nnano', u'sru:recordData': {u'pam:message': {u'pam:article': {}}}, u'prism:copyright': u'\\xa9 2011 Nature Publishing Group', u'prism:issn': u'1748-3387', u'dc:subject': None, u'dc:identifier': u'doi:10.1038/nnano.2011.249', u'sru:recordSchema': u'info:srw/schema/11/pam-v2.1', u'id': u'http://dx.doi.org/10.1038/nnano.2011.249', u'content': None, u'prism:genre': u'Research', u'prism:startingPage': u'180', u'prism:number': u'3', u'sru:recordPacking': u'unpacked', u'dc:description': u'<p>Deciphering the neuronal code\\u2014the rules by which neuronal circuits store and process information\\u2014is a major scientific challenge. Currently, these efforts are impeded by a lack of experimental tools that are sensitive enough to quantify the strength of individual synaptic connections and also scalable enough to simultaneously measure and control a large number of mammalian neurons with single-cell resolution. Here, we report a scalable intracellular electrode platform based on vertical nanowires that allows parallel electrical interfacing to multiple mammalian neurons. Specifically, we show that our vertical nanowire electrode arrays can intracellularly record and stimulate neuronal activity in dissociated cultures of rat cortical neurons and can also be used to map multiple individual synaptic connections. The scalability of this platform, combined with its compatibility with silicon nanofabrication techniques, provides a clear path towards simultaneous, high-fidelity interfacing with hundreds of individual neurons.</p>', u'updated': u'2014-12-23T12:16:15+00:00', u'title': u'Vertical nanowire electrode arrays as a scalable platform for intracellular interfacing to neuronal circuits', u'prism:endingPage': u'184', u'sru:recordPosition': 1, u'sru:extraRecordData': {u'entry': []}, u'dc:creator': [u'Jacob T. Robinson', u'Marsela Jorgolli', u'Alex K. Shalek', u'Myung-Han Yoon', u'Rona S. Gertner', u'Hongkun Park'], u'prism:channel': None, u'prism:section': None, u'prism:publicationDate': u'2012-01-10', u'prism:coverDate': None, u'prism:eIssn': u'1748-3395', u'prism:aggregationType': None, u'link': u'http://dx.doi.org/10.1038/nnano.2011.249', u'prism:url': u'http://dx.doi.org/10.1038/nnano.2011.249'}\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## crawl IEEE Xplore\n",
      "#keyword = urllib.quote_plus(\"graphene\")\n",
      "#url = \"http://ieeexplore.ieee.org/gateway/ipsSearch.jsp?&hc=1&querytext=\" + keyword\n",
      "#content = urllib2.urlopen(url).read()\n",
      "#tree = ET.fromstring(content)\n",
      "#for child in tree.iter('title'):\n",
      "#   print child.text\n",
      "#\n",
      "## crawl Springer\n",
      "#url = 'http://api.springer.com/metadata/json?p=100&q=title:graphene&api_key=3a3sxqg25fmwnzrsy2qmgjds'\n",
      "#content = urllib2.urlopen(url).read()\n",
      "#data = json.loads(content)\n",
      "#for record in data['records']:\n",
      "#   print record['title'].encode('utf-8')\n",
      "#   #print record['doi'].encode('utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}